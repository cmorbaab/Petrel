{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "import os\n",
    "from snorkel.parser import XMLMultiDocPreprocessor\n",
    "\n",
    "# The following line is for testing only. Feel free to ignore it.\n",
    "file_path = 'articles/training.xml'\n",
    "train_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//article',\n",
    "    text='.//front/article-meta/abstract/p/text()',\n",
    "    id=  './/front/article-meta/article-id/text()'\n",
    ")\n",
    "\n",
    "file_path = 'articles/development.xml'\n",
    "dev_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,    \n",
    "    doc='.//document',    \n",
    "    text='.//passage/text/text()',    \n",
    "    id='.//id/text()'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "corpus_parser = CorpusParser()\n",
    "corpus_parser.apply(list(train_preprocessor)) #parallelism can be run with a Postgres DBMS, but not SQLite\n",
    "corpus_parser.apply(list(dev_preprocessor), clear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves.cPickle import load\n",
    "\n",
    "with open('articles/doc_ids.pkl', 'rb') as f:\n",
    "    train_ids, dev_ids = load(f)\n",
    "train_ids, dev_ids = set(train_ids), set(dev_ids)\n",
    "print len(train_ids)\n",
    "print len(dev_ids)\n",
    "train_sents, dev_sents = set(), set()\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "print docs\n",
    "print len(docs)\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        else:\n",
    "            raise Exception('ID <{0}> not found in any id set'.format(doc.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "\n",
    "BiomarkerDrug = candidate_subclass('BiomarkerDrug', ['biomarker', 'drug'])\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher\n",
    "import matchers\n",
    "from snorkel.models import Document\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "import os\n",
    "\n",
    "biomarker_ngrams = Ngrams(n_max=1)\n",
    "drug_ngrams = Ngrams(n_max=5)\n",
    "\n",
    "# Create our two Matchers\n",
    "bMatcher = matchers.getBiomarkerMatcher()\n",
    "dMatcher = matchers.getDrugMatcher()\n",
    "    \n",
    "# Building the CandidateExtractor \n",
    "candidate_extractor = CandidateExtractor(BiomarkerDrug, [biomarker_ngrams, drug_ngrams], [bMatcher, dMatcher])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents]):\n",
    "    candidate_extractor.apply(sents, split=k)\n",
    "    print(\"Number of candidates:\", session.query(BiomarkerDrug).filter(BiomarkerDrug.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyWords = ['basis', 'target', 'treat', 'treatment', 'inhibit', 'inhibition', 'inhibitor', ]\n",
    "negationWords = [\"not\", \"nor\", \"neither\"]\n",
    "\n",
    "def presenceOfNot(m):\n",
    "    for word in negationWords:\n",
    "        if (word in m.post_window1('lemmas', 20)) and (word in m.pre_window2('lemmas', 20)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 1\n",
    "def LF_distance(m):\n",
    "    # if 'neuroendocrine' in m.lemmas:\n",
    "    #     print m.lemmas \n",
    "    # print m.dep_labels\n",
    "    distance = abs(m.e2_idxs[0] - m.e1_idxs[0])\n",
    "    count = 0\n",
    "    for lemma in m.lemmas:\n",
    "        if lemma == ',':\n",
    "            count += 1\n",
    "    if count > 1 and ',' in m.pre_window1('lemmas', 1):\n",
    "        print m\n",
    "        return 0\n",
    "    if distance == 0:\n",
    "        return -1\n",
    "    if distance < 8:\n",
    "        # print \"RETURNING ONE\"\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def LF_keyword(m):\n",
    "    for word in keyWords:\n",
    "        if ((word in m.post_window1('lemmas', 20)) and (word in m.pre_window2('lemmas', 20))) or ((word in m.post_window1('lemmas', 20)) and (word in m.pre_window2('lemmas', 20))):\n",
    "            if presenceOfNot(m):\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def LF_usedToTreat(m):\n",
    "     if ('used' in m.pre_window1('lemmas'), 20) and ('to' in m.pre_window1('lemmas', 20)) and ('treat' in m.pre_window1('lemmas', 20)):\n",
    "         return 1\n",
    "     else:\n",
    "         return 0\n",
    "     \n",
    "def LF_usedToInhibit(m):\n",
    "     if ('used' in m.pre_window1('lemmas'), 20) and ('to' in m.pre_window1('lemmas', 20)) and ('inhibit' in m.pre_window1('lemmas', 20)):\n",
    "         return 1\n",
    "     else:\n",
    "         return 0\n",
    "     \n",
    "def LF_inhibit(m):\n",
    "    if ('inhibit' in m.pre_window1('lemmas', 20) and 'inhibit' in m.pre_window2('lemms', 20)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_target(m):\n",
    "    if ('target' in m.pre_window1('lemmas', 20) and 'target' in m.pre_window2('lemms', 20)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_inhibitionOfWith(m):\n",
    "    if ('inhibition' in m.pre_window1('lemmas', 20) and 'of' in m.pre_window1('lemmas', 20) and 'with' in m.post_window1('lemmas', 20)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_isATreatmentOf(m):\n",
    "    if ('is' in m.pre_window1('lemmas', 20) and 'a' in m.pre_window1('lemmas', 20) and 'treatment' in m.pre_window1('lemmas', 20) and 'of' in m.pre_window1('lemmas', 20)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_antibody(m):\n",
    "    if ('antibody' in m.post_window2('lemmas', 20)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def LF_hadisbad(m):\n",
    "    if(m.mention1 == \"had\" or m.mention2 == \"had\"):\n",
    "        return -1\n",
    "def LF_duration(m):\n",
    "    if(m.mention1 == \"duration\" or m.mention2 == \"duration\"):\n",
    "        return -1\n",
    "def LF_isaBiomarker(m):\n",
    "    post_window1_lemmas = m.post_window1('lemmas',20)\n",
    "    pre_window2_lemmas = m.pre_window2('lemmas',20)\n",
    "    if ('biomarker' in post_window1_lemmas and 'biomarker' in pre_window2_lemmas) or ('marker' in post_window1_lemmas and 'marker' in pre_window2_lemmas) or ('indicator' in post_window1_lemmas and 'indicator' in pre_window2_lemmas):\n",
    "        marker_idx_post_window1 = -1\n",
    "        markers = ['biomarker','marker','indicator']\n",
    "        for marker in markers:\n",
    "            try:\n",
    "                # print post_window1_lemmas\n",
    "                findMarker = post_window1_lemmas.index(marker)\n",
    "                if not findMarker == -1:\n",
    "                    marker_idx_post_window1 = findMarker\n",
    "                    print marker\n",
    "            except:\n",
    "                pass\n",
    "        if 'cop' in m.post_window1('dep_labels',20):\n",
    "            try:\n",
    "                cop_idx_post_window1 = m.post_window1('dep_labels',20).index('cop')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print \"MarkerIdx:\"\n",
    "            print marker_idx_post_window1\n",
    "            print \"ROOTIdx:\"\n",
    "            try:\n",
    "                print  m.post_window1('dep_labels',marker_idx_post_window1)\n",
    "                print  m.post_window1('dep_labels',marker_idx_post_window1).index('ROOT')\n",
    "            except:\n",
    "                pass\n",
    "            print '\\n'\n",
    "            \n",
    "            return 1 if ('nsubj' in m.mention1(attribute='dep_labels')) and (marker_idx_post_window1-cop_idx_post_window1 < 4)  else 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [LF_distance, LF_keyword, LF_usedToTreat, LF_inhibit, LF_inhibitionOFWith, LF_isaBiomarker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deps = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print L_gold_dev\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "print L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_external_annotations_new import load_external_labels\n",
    "load_external_labels(session, BiomarkerDrug, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = gen_model.score(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dev labels and convert to [0, 1] range\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "dev_labels = (np.ravel(L_gold_dev.todense()) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "%time F_train = featurizer.apply(split=0)\n",
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "F_dev  = featurizer.apply_existing(split=1)\n",
    "F_test = featurizer.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, F_train, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "disc_model = SparseLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "searcher = RandomSearch(session, disc_model, F_train, train_marginals, [rate_param, l1_param, l2_param], n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "searcher.fit(F_dev, L_gold_dev, n_epochs=50, rebalance=0.5, print_freq=25)\n",
    "\n",
    "### Scoring on the test set\n",
    "\n",
    "Finally, we'll evaluate our performance on the blind test set of 500 documents. We'll load labels similar to how we did for the development set, and use the `score` function of our extraction model to see how we did.\n",
    "\n",
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, BiomarkerDrug, split=2, annotator='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test\n",
    "\n",
    "_, _, _, _ = disc_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   50,\n",
    "    'dropout':    0.5,\n",
    "    'rebalance':  0.25,\n",
    "    'print_freq': 5\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train, train_marginals, dev_candidates=dev, dev_labels=dev_labels, **train_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
