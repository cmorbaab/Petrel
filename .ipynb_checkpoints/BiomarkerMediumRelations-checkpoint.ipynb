{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "import os\n",
    "from snorkel.parser import XMLMultiDocPreprocessor\n",
    "\n",
    "# The following line is for testing only. Feel free to ignore it.\n",
    "file_path = 'articles/training.xml'\n",
    "train_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//article',\n",
    "    text='.//front/article-meta/abstract/p/text()',\n",
    "    id=  './/front/article-meta/article-id/text()'\n",
    ")\n",
    "\n",
    "file_path = 'articles/development.xml'\n",
    "dev_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,    \n",
    "    doc='.//document',    \n",
    "    text='.//passage/text/text()',    \n",
    "    id='.//id/text()'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "corpus_parser = CorpusParser()\n",
    "corpus_parser.apply(list(train_preprocessor)) #parallelism can be run with a Postgres DBMS, but not SQLite\n",
    "corpus_parser.apply(list(dev_preprocessor), clear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves.cPickle import load\n",
    "\n",
    "with open('articles/doc_ids.pkl', 'rb') as f:\n",
    "    train_ids, dev_ids = load(f)\n",
    "train_ids, dev_ids = set(train_ids), set(dev_ids)\n",
    "print len(train_ids)\n",
    "print len(dev_ids)\n",
    "train_sents, dev_sents = set(), set()\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "print docs\n",
    "print len(docs)\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        else:\n",
    "            raise Exception('ID <{0}> not found in any id set'.format(doc.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "\n",
    "BiomarkerMedium = candidate_subclass('BiomarkerMedium', ['biomarker', 'medium'])\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher\n",
    "import matchers\n",
    "from snorkel.models import Document\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "import os\n",
    "\n",
    "biomarker_ngrams = Ngrams(n_max=1)\n",
    "medium_ngrams = Ngrams(n_max=5)\n",
    "\n",
    "# Create our two Matchers\n",
    "bMatcher = matchers.getBiomarkerMatcher()\n",
    "mMatcher = matchers.getMediumMatcher()\n",
    "    \n",
    "# Building the CandidateExtractor \n",
    "candidate_extractor = CandidateExtractor(BiomarkerMedium, [biomarker_ngrams, medium_ngrams], [bMatcher, mMatcher])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents]):\n",
    "    candidate_extractor.apply(sents, split=k)\n",
    "    print(\"Number of candidates:\", session.query(BiomarkerMedium).filter(BiomarkerMedium.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_keyword_lemmas = [\"contain\", \"collect\", \"find\", \"sample\", \"fluid\", \"tissue\", \"detection\"]\n",
    "sentences = []\n",
    "# 1- distance far\n",
    "def LF_distance_far(m):\n",
    "    # print m.lemmas\n",
    "    # print m.dep_labels\n",
    "    distance = abs(m.e2_idxs[0] - m.e1_idxs[0])\n",
    "    if distance < 10:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "            \n",
    "# 2- distance close\n",
    "def LF_distance_close(m):\n",
    "    # print m.lemmas\n",
    "    # print m.dep_labels\n",
    "    distance = abs(m.e2_idxs[0] - m.e1_idxs[0])\n",
    "    if distance < 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 3-  Biomarker + preposition + Medium\n",
    "def LF_IN(m):\n",
    "    return 1 if (('IN' in m.post_window1('poses', 5) and 'IN' in m.pre_window2('poses',5))) or (('IN' in m.post_window2('poses', 5) and 'IN' in m.pre_window1('poses',5))) else 0 \n",
    "         \n",
    "# 4- If the sentence contains common keywords\n",
    "def LF_keyword(m):\n",
    "    for word in sentence_keyword_lemmas:\n",
    "        if (word in m.pre_window1('lemmas',20)) or (word in m.post_window1('lemmas',20)):\n",
    "            #if presenceOfNot(m):\n",
    "            #    return -1\n",
    "            #else:\n",
    "            #    return 1\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# 5- Medium \"from\" patients or subjects\n",
    "def LF_From(m):\n",
    "    index = 0\n",
    "    post = m.post_window2('lemmas',20)\n",
    "    if 'patient' in post:\n",
    "        index = post.index('patient')\n",
    "    elif 'subject' in post:\n",
    "        index = post.index('subject')\n",
    "    return 1 if \"from\" in m.post_window2('lemmas',index) else 0\n",
    "\n",
    "# 6- Medium \"-based\": blood-based biomarker\n",
    "def LF_based(m):\n",
    "    mediumBased = m.mention2(attribute='words') + \"-based\"\n",
    "    return 1 if mediumBased in m.pre_window1('words',20) or mediumBased in m.post_window1('words',20) else 0\n",
    "\n",
    "# 7- Medium \"biomarker\": blood biomarker\n",
    "def LF_biomarker(m):\n",
    "    return 1 if 'biomarker' in m.post_window2('lemmas',3) else 0\n",
    "\n",
    "# 8- if that relationship is in the references, MIGHT NOT WORK\n",
    "def LF_References(m):\n",
    "    sent_id = m.post_window1('sent_id',1)\n",
    "    sentences_before = sentences[0:sent_id]\n",
    "    for sentence in sentences_before:\n",
    "        if 'References' in sentence.words():\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [LF_distance_far, LF_distance_close, LF_IN, LF_keyword, LF_From, LF_based, LF_biomarker, LF_References]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deps = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print L_gold_dev\n",
    "L_dev = labeler.apply_existing(split=1)\n",
    "print L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_external_annotations_new import load_external_labels\n",
    "load_external_labels(session, BiomarkerMedium, 'Biomarker', 'Medium', 'articles/medium_gold_labels.tsv', annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = gen_model.score(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dev labels and convert to [0, 1] range\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "dev_labels = (np.ravel(L_gold_dev.todense()) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "%time F_train = featurizer.apply(split=0)\n",
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "F_dev  = featurizer.apply_existing(split=1)\n",
    "F_test = featurizer.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, F_train, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "disc_model = SparseLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "searcher = RandomSearch(session, disc_model, F_train, train_marginals, [rate_param, l1_param, l2_param], n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "searcher.fit(F_dev, L_gold_dev, n_epochs=50, rebalance=0.5, print_freq=25)\n",
    "\n",
    "### Scoring on the test set\n",
    "\n",
    "Finally, we'll evaluate our performance on the blind test set of 500 documents. We'll load labels similar to how we did for the development set, and use the `score` function of our extraction model to see how we did.\n",
    "\n",
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, BiomarkerDrug, split=2, annotator='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test\n",
    "\n",
    "_, _, _, _ = disc_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   50,\n",
    "    'dropout':    0.5,\n",
    "    'rebalance':  0.25,\n",
    "    'print_freq': 5\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train, train_marginals, dev_candidates=dev, dev_labels=dev_labels, **train_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
